{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u7ju5sqntb8",
        "outputId": "35e60af3-03c1-49d7-ef49-74ffe8149ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXjQJM75oQtt",
        "outputId": "1a95628b-2a4b-4cd1-d8d4-d7398d063259"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data extracted!\n",
            "Validation Accuracy: 0.7590\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77       500\n",
            "           1       0.78      0.73      0.75       500\n",
            "\n",
            "    accuracy                           0.76      1000\n",
            "   macro avg       0.76      0.76      0.76      1000\n",
            "weighted avg       0.76      0.76      0.76      1000\n",
            "\n",
            "Test Accuracy: 0.7677\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.78      0.77       831\n",
            "           1       0.78      0.75      0.76       831\n",
            "\n",
            "    accuracy                           0.77      1662\n",
            "   macro avg       0.77      0.77      0.77      1662\n",
            "weighted avg       0.77      0.77      0.77      1662\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def extract_data(file_path):\n",
        "    if file_path.endswith(\".tar.gz\"):\n",
        "        with tarfile.open(file_path, \"r:gz\") as tar:\n",
        "            tar.extractall()\n",
        "            print(\"Data extracted!\")\n",
        "\n",
        "extract_data(\"rt-polaritydata.tar.gz\")\n",
        "\n",
        "def load_data():\n",
        "    with open('rt-polaritydata/rt-polarity.pos', 'r', encoding='ISO-8859-1') as pos_file:\n",
        "        pos_sentences = pos_file.readlines()\n",
        "    with open('rt-polaritydata/rt-polarity.neg', 'r', encoding='ISO-8859-1') as neg_file:\n",
        "        neg_sentences = neg_file.readlines()\n",
        "\n",
        "    pos_df = pd.DataFrame(pos_sentences, columns=['review'])\n",
        "    pos_df['label'] = 1\n",
        "\n",
        "    neg_df = pd.DataFrame(neg_sentences, columns=['review'])\n",
        "    neg_df['label'] = 0\n",
        "\n",
        "    return pos_df, neg_df\n",
        "\n",
        "pos_df, neg_df = load_data()\n",
        "\n",
        "def split_data(pos_df, neg_df):\n",
        "    pos_train = pos_df.iloc[:4000]\n",
        "    pos_val = pos_df.iloc[4000:4500]\n",
        "    pos_test = pos_df.iloc[4500:]\n",
        "\n",
        "    neg_train = neg_df.iloc[:4000]\n",
        "    neg_val = neg_df.iloc[4000:4500]\n",
        "    neg_test = neg_df.iloc[4500:]\n",
        "\n",
        "    train_data = pd.concat([pos_train, neg_train]).sample(frac=1).reset_index(drop=True)\n",
        "    val_data = pd.concat([pos_val, neg_val]).sample(frac=1).reset_index(drop=True)\n",
        "    test_data = pd.concat([pos_test, neg_test]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "train_data, val_data, test_data = split_data(pos_df, neg_df)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text.lower())\n",
        "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "train_data['review'] = train_data['review'].apply(preprocess_text)\n",
        "val_data['review'] = val_data['review'].apply(preprocess_text)\n",
        "test_data['review'] = test_data['review'].apply(preprocess_text)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_data['review'])\n",
        "X_val = vectorizer.transform(val_data['review'])\n",
        "X_test = vectorizer.transform(test_data['review'])\n",
        "\n",
        "y_train = train_data['label']\n",
        "y_val = val_data['label']\n",
        "y_test = test_data['label']\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "val_predictions = clf.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(classification_report(y_val, val_predictions))\n",
        "\n",
        "test_predictions = clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(classification_report(y_test, test_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD_wb9ayCDbF",
        "outputId": "a9b03448-ecb0-4758-e74e-e28b4c75b6f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results:\n",
            "TP: 364, TN: 395, FP: 105, FN: 136\n",
            "Precision: 0.7761\n",
            "Recall: 0.7280\n",
            "F1 Score: 0.7513\n",
            "\n",
            "Test Results:\n",
            "TP: 625, TN: 651, FP: 180, FN: 206\n",
            "Precision: 0.7764\n",
            "Recall: 0.7521\n",
            "F1 Score: 0.7641\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "val_predictions = clf.predict(X_val)\n",
        "\n",
        "cm = confusion_matrix(y_val, val_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Validation Results:\")\n",
        "print(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "test_predictions = clf.predict(X_test)\n",
        "\n",
        "cm_test = confusion_matrix(y_test, test_predictions)\n",
        "tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
        "\n",
        "precision_test = tp_test / (tp_test + fp_test)\n",
        "recall_test = tp_test / (tp_test + fn_test)\n",
        "f1_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
        "\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"TP: {tp_test}, TN: {tn_test}, FP: {fp_test}, FN: {fn_test}\")\n",
        "print(f\"Precision: {precision_test:.4f}\")\n",
        "print(f\"Recall: {recall_test:.4f}\")\n",
        "print(f\"F1 Score: {f1_test:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
